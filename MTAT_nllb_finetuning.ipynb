{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10931104,
          "sourceType": "datasetVersion",
          "datasetId": 6796905
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "MTAT -- nllb_finetuning",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiterharris/Assignment-1/blob/master/MTAT_nllb_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning NLLB"
      ],
      "metadata": {
        "id": "rCjpt16CmM4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Set Up the Environment\n",
        "\n",
        "Kaggle’s default environment has transformers, but you might need to install other dependencies like datasets and sentencepiece."
      ],
      "metadata": {
        "id": "FK4KLxMWmM4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate bitsandbytes\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:01:54.239672Z",
          "iopub.execute_input": "2025-03-19T15:01:54.239915Z",
          "iopub.status.idle": "2025-03-19T15:02:03.778676Z",
          "shell.execute_reply.started": "2025-03-19T15:01:54.239894Z",
          "shell.execute_reply": "2025-03-19T15:02:03.777809Z"
        },
        "id": "XkP20FHOmM4t",
        "outputId": "92231736-d938-4424-bc62-51e270b7bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load Your Data\n",
        "\n",
        "Since you have sentence-aligned files, you need to prepare them in a format suitable for datasets (e.g., a TSV or JSON).\n",
        "Example: Loading TSV Aligned Data\n",
        "\n",
        "If your data is in two aligned text files"
      ],
      "metadata": {
        "id": "nwx-piiMmM4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load sentence-aligned files\n",
        "with open(\"/kaggle/input/mtat25-ted-data-test/data/TED2020.de-en.de.train\", \"r\", encoding=\"utf-8\") as src, open(\"/kaggle/input/mtat25-ted-data-test/data/TED2020.de-en.en.train\", \"r\", encoding=\"utf-8\") as tgt:\n",
        "    src_lines = src.readlines()[:3000]\n",
        "    tgt_lines = tgt.readlines()[:3000]\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame({\"source\": src_lines, \"target\": tgt_lines})\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset = dataset.shuffle()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:02:59.130542Z",
          "iopub.execute_input": "2025-03-19T15:02:59.130837Z",
          "iopub.status.idle": "2025-03-19T15:03:02.502802Z",
          "shell.execute_reply.started": "2025-03-19T15:02:59.130815Z",
          "shell.execute_reply": "2025-03-19T15:03:02.502164Z"
        },
        "id": "S2LYOxIUmM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Pretrained NLLB Model\n",
        "\n",
        "NLLB models are available in different sizes on Hugging Face:\n",
        "\n",
        "    facebook/nllb-200-distilled-600M (medium)\n",
        "    facebook/nllb-200-1.3B (large)\n",
        "    facebook/nllb-200-3.3B (very large)\n",
        "\n",
        "Choose a smaller model (e.g., 600M) if running in Kaggle to avoid RAM issues."
      ],
      "metadata": {
        "id": "KKqAyTWzmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:06:12.100553Z",
          "iopub.execute_input": "2025-03-19T15:06:12.100885Z",
          "iopub.status.idle": "2025-03-19T15:06:57.524241Z",
          "shell.execute_reply.started": "2025-03-19T15:06:12.100858Z",
          "shell.execute_reply": "2025-03-19T15:06:57.523228Z"
        },
        "id": "Vdha4B_WmM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Tokenize Data\n",
        "\n",
        "NLLB requires a special language token identifier (<2xx>). Find the correct tokens for your source and target languages from NLLB language codes.\n",
        "\n",
        "For example, if translating German → English:"
      ],
      "metadata": {
        "id": "8PWTaF5zmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANG = \"<deu_Latn>\"\n",
        "TGT_LANG = \"<eng_Latn>\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [SRC_LANG + text.strip() for text in examples[\"source\"]]\n",
        "    #targets = [TGT_LANG + text.strip() for text in examples[\"target\"]]\n",
        "    targets = [text.strip() for text in examples[\"target\"]]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:08:23.095146Z",
          "iopub.execute_input": "2025-03-19T15:08:23.096238Z",
          "iopub.status.idle": "2025-03-19T15:08:24.008582Z",
          "shell.execute_reply.started": "2025-03-19T15:08:23.096206Z",
          "shell.execute_reply": "2025-03-19T15:08:24.007726Z"
        },
        "id": "taGBqo46mM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Set Up Training Arguments\n",
        "\n",
        "Define the training arguments using Hugging Face’s Trainer API."
      ],
      "metadata": {
        "id": "VMgB4xbnmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./nllb-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=1,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:10:56.341795Z",
          "iopub.execute_input": "2025-03-19T15:10:56.342092Z",
          "iopub.status.idle": "2025-03-19T15:10:56.375266Z",
          "shell.execute_reply.started": "2025-03-19T15:10:56.342072Z",
          "shell.execute_reply": "2025-03-19T15:10:56.374287Z"
        },
        "id": "5PoJ-q-DmM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Define Data Collator and Trainer\n",
        "\n",
        "Use DataCollatorForSeq2Seq to handle padding efficiently."
      ],
      "metadata": {
        "id": "eHf7CiHbmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq, Trainer\n",
        "\n",
        "# Data collator for padding sequences\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    eval_dataset=tokenized_datasets,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:11:05.722442Z",
          "iopub.execute_input": "2025-03-19T15:11:05.72276Z",
          "iopub.status.idle": "2025-03-19T15:11:05.737804Z",
          "shell.execute_reply.started": "2025-03-19T15:11:05.722733Z",
          "shell.execute_reply": "2025-03-19T15:11:05.736965Z"
        },
        "id": "FqxGMljCmM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Start Training\n",
        "\n",
        "Now, you can start finetuning."
      ],
      "metadata": {
        "id": "bGEsEz-nmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:11:11.743151Z",
          "iopub.execute_input": "2025-03-19T15:11:11.743513Z",
          "iopub.status.idle": "2025-03-19T15:23:01.734263Z",
          "shell.execute_reply.started": "2025-03-19T15:11:11.743487Z",
          "shell.execute_reply": "2025-03-19T15:23:01.733357Z"
        },
        "id": "IPmY28RTmM4u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Save and Download Model\n",
        "\n",
        "Once training is complete, save the model and tokenizer."
      ],
      "metadata": {
        "id": "jpOdOj2HmM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"nllb-finetuned-no-target-tag\")\n",
        "tokenizer.save_pretrained(\"nllb-finetuned-no-target-tag\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T15:23:25.19364Z",
          "iopub.execute_input": "2025-03-19T15:23:25.193986Z",
          "iopub.status.idle": "2025-03-19T15:23:30.924899Z",
          "shell.execute_reply.started": "2025-03-19T15:23:25.193958Z",
          "shell.execute_reply": "2025-03-19T15:23:30.924122Z"
        },
        "id": "do8g71kdmM4u"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}